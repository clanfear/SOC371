<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Measuring Crime and Policing</title>
    <meta charset="utf-8" />
    <meta name="author" content="Chuck Lanfear" />
    <script src="libs/header-attrs-2.2/header-attrs.js"></script>
    <link rel="stylesheet" href="..\style\xaringan-themer.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, top, title-slide

# Measuring Crime and Policing
## SOC371, Summer 2020
### Chuck Lanfear
### Jul 6, 2020<br>Updated: Jul 6, 2020

---




# Overview

1. Research Approaches

2. Measuring Crime

   * Police Data
   
   * Victimization
   
   * Self-Report

3. Measurement and Levels of Explanation

   * Individual Characteristics

   * Groups and Places
   
4. Measuring Relationships
 
   * Types of Effects

   * Measuring Bias in Policing

---
# Take Methods Courses

Today is a brief overview of Sociological methods.

These topics are too much to cover in one term let alone a day.

--

To get a foundation in these topics, I recommend you...

* Take a course in *research design*
   + SOC300: Foundations of Social Inquiry
   + SOC403: Applied Research 

* Take a course in *research methods*
   + SOC/STAT/CS&amp;SS221: Statistical Concepts and Methods
   + SOC321: Data Science and Statistics

???

Many of the advanced methods you see in modern papers aren't seen in any undergraduate classes; sometimes not even in grad classes.

---
class: inverse
# Research Approaches 

### Qualitative and quantitative

.pull-left[
.image-75[
![](img/suttles.jpg)
]
]

.pull-right[
.image-75[
![](img/sampson.jpg)
]
]

---

# Qualitative

*Contextual, categorical, interpretive, inductive*

Data

* Interviews
* Observation (Overt/Covert)
* Participation (Overt/Covert)

--

.pull-left[
Strengths

* Access hidden populations
* Capture context and meaning
* Observe mechanisms
* Easier to Communicate
]

???


Qual work often inductive: looks at specific cases and extrapolates to general theory; the specific to the general

Qualitative work can get at lived experiences

Qualitative work often only way to get offender perspectives

Pops you want to reach can be risky or difficult to access

But can ask and answer questions from perspective of agents involved

Can capture whole processes including motivations and feelings of actors involved

--

.pull-right[
Challenges

* Research time requirements
   + Scales poorly
* Subjectivity at forefront
* Risk and access
* Replication / Generalizability
]

???

Qual work typically huge time commitment

Must address subjectivity--different researchers will interpret situations differently

Possible to get swept into ethical issues: Alice Goffman's *On The Run*

   + Most charitable interpretation is being uncritical of informant claims, getting swept up in their lives
   + Less charitable (but possibly true) is substantial fabrication and unethical behavior

---
# Quantitative

*Abstract, numeric, hypothetical, deductive*

Data

* Surveys
* Secondary data
   + Police Data
   + Government Data

???

Quant work often deductive: Begins with general rules, tests hypotheses and applies to cases; the general to the specific

Might also use novel things like sensors or social media data

--

.pull-left[
Strengths

* Replication / Generalizability
* Testing and validating
* Measuring effects
* Scales well
]

???

Quant research can typically be reproduced computationally, replicated statistically, and more easily generalized to new contexts

Can get precise, actionable numeric estimates for policy

Can use gross amounts of data that are impossible to handle qualitatively

--

.pull-right[
Challenges

* Up-front time requirements
* Homogenizes population and context
* Data demands
* Hidden subjectivity
* Harder to communicate
]

???

Learning to do quant research well is an enormous undertaking--and even the best make major mistakes

Can easily miss important heterogeneity; can also miss important mechanisms that would be obvious from qualitative research

Data needs to be available--this means small or hidden pops go unstudied

Different researchers will make different choices in data cleaning and modeling


---
# Feedback Loop

.image-short[
![](img/quant_qual_loop.svg)
]

???

This is an idealized model--quant work can uncover some mechanisms, qual work often reveals anomalies.

There's also some great qualitative work that tests propositions! Can be dismissed by pure quant people--but ignore that dogma

In general though, it is inadvisable for any area to focus too heavily on either--creates blind spots

Also wastes effort as people focus on the wrong mechanisms (quant) or overgeneralize rare cases (qual)

Both are filled with bad takes

---
class: inverse
# Measuring Crime

---
# Police Data


Uniform Crime Report

* Agency-period units
* Hierarchy rule
* High participation

National Incident Based Reporting System

* Incident units
* No hierarchy
* Lower participation

Agency Data

* Unique to department

???

Police data is administrative data--a form of secondary data collected by agencies for their own uses.

It isn't generated for research purposes, so there is little concern for things researchers care about like sample representation

---
# The Dark Figure of Crime

.pull-left[
* Not all crimes are discovered

   + Victimless crimes
   + Missing person homicides

* Not all crimes are reported

   + Varies by place
   + Varies by individuals
   + Varies by crime

* Not all reported are recorded by police

   + Varies by agency
   + Varies by crime
   + Political incentives
   + Differential treatment

]
.pull-right[
.image-short[
![](img/dark_figure.jpg)
]
]

???

The Wire: Police are often under pressure to reduce the crime rate; easiest way to do that is avoid charging people; juking stats

If police believe DA won't pursue, they won't either

This means better enforcement makes crime go up

Differential treatment may produce bias not seen in actual commission of crimes

---
# An Example

*Observed Crime Rate* `\(=\)` *Actual Rate* `\(*\)` *Probability of Reporting*

&lt;br&gt;

--

&gt; According to the U.C.R., the incidence of rape nearly doubled from 1973 to 1990. The N.C.V.S., by contrast, shows that it declined by around forty per cent during the same period. Researchers... found that the upward trend in the U.C.R. data correlated with upticks in the number of female police officers, and with the advent of rape crisis centers and reformed investigative styles. It could be, in short, that a modernized approach to the policing of rape drastically increased the frequency with which it was reported while reducing its incidence.

[Matthew Hutson. 2020. "The Trouble with Crime Statistics." *The New Yorker*](https://www.newyorker.com/culture/annals-of-inquiry/the-trouble-with-crime-statistics)

???

In this case many things mattered for determining apparent rape rates

Police practices, police identities, victim characteristics, and supporting services

Changing understandings of consent, fear of victim blaming, cultural support likely to have effects too

Good lay person article

---
# Victimization Data

.pull-left[
Advantages

* Captures unreported crime
* Can get at exposure
]

--

.pull-right[
Challenges

* Reluctance to answer
* Hidden populations
* Relived trauma
* Sampling: Expense and coverage
* Doesn't capture crime without victim
]

???

If you survey a person, you get their victimization; hard to track over time, or many people

Crime without victim includes consensuals but also homicide

Missing and murdered indigenous women and girls

--

Examples:

National Crime Victimization Survey

Seattle Neighborhoods and Crime Survey

Durfee. 2011. "'I’m Not a Victim, She's an Abuser'": Masculinity, Victimization, and Protection Orders."



---
# Self-Report Data

.pull-left[
Advantages

* Captures unreported crime
* Captures crime without victim
* Can get at motivation
]

--

.pull-right[
Challenges

* Reluctance to answer
* Hidden, even dangerous, populations
* Easier to get youth than adults
* Many crimes very rare
* Sampling: Expense and coverage

]

???

Random sampling means basically impossible to reach enough for national, hard even in city

Targeted samples have limitations

Separation between incarcerated and free samples

--

Examples:

National Longitudinal Survey of Youth

Add Health

St. Jean. 2007. *Pockets of Crime: Broken Windows, Collective Efficacy, and the Criminal Point of View*


---
class: inverse

# Measurement and Levels of Explanation

---
# Types of Measures

&amp;zwj;Observables: Objective, externally measurable variables

   * Individual height, occupation, stated opinions
   * Neighborhood population, size, crime rate&lt;sup&gt;1&lt;/sup&gt;

.footnote[[1] Hard to measure doesn't mean unobservable!]

*Observables can be directly seen and/or experienced*

--

Unobservables (Constructs): Subjective, internal, or only indirectly measurable

   * Individual self-control, wellness, social class
   * Neighborhood social capital, heterogeneity, disadvantage

*Unobservables do not exist in the real world: they are conceptual*

--

In Criminology, we're *very often* interested in unobservables.


???

Unobservables of individuals are usually not even internally verifiable or measurable.

Unobservables can mean something different to everyone.

These are ideal types. Some theoretically observable things must be treated as unobservable. Sometimes unobservables are treated as observable.

---
# Measurement Concepts

&amp;zwj;Conceptualization: *What is X?*

* Define what a measure constitutes
* Define relations to other concepts
* Goal: Minimize ambiguity

???

Important thing here is being clear about what is meant

What does social class mean?

--

&amp;zwj;Operationalization: *How do I measure X?*

* Define observable(s)--**indicators**--that are related to the concept
* If single indicator, it is a **proxy** for the concept
   + e.g. *Years of School* is a proxy for *Education*
* If multiple indicators, they can be combined into *composite* measure&lt;sup&gt;1&lt;/sup&gt;

When reading articles, pay attention to how things are measured!

.footnote[[1] Composites include things like indices, scales, factors, and principle components. Turning multiple measures into one composite is sometimes called *dimension reduction*.]

???

Conceptualization and operationalization are tricky and can lead to lots of arguments

When you read articles, try to follow the logic. If there's a disconnect between concept and measures, it might signal a problem.

If someone wants to know the effect of social class in crime but only uses income, they're looking at the association of income.

If income + education, they're looking at some average of those two. Are those social class? There are high class people with low educations and incomes and low class people with high educations and high income.

---
## Individual Example

### Self-Control

&amp;zwj;Concept: The ability to delay gratification, tolerate frustration, and carefully consider before acting.

--

&amp;zwj;Measures: *Would you strongly agree, somewhat agree, or disagree that you...*

   * "Get upset when you have to wait for something?"
   * "Act without stopping to think?"
   * "Like to do daring things?"
   * "Are impatient--want to have things right away?"
   * "Are careful about what you do?"
   
--

&amp;zwj;Assumption: *Shared variation in the measures represents underlying self-control.*

---
# Neighborhood Example

### Expectations for Child-Centered Informal Control

&amp;zwj;Concept: The shared neighborhood norms and expectations for intervening against child misbehavior.

???

This is a complex one that we'll see a bunch in social disorg--mainly collective efficacy

Idea is capturing neighborhood capacity to control child behavior in public spaces

Isn't about what respondent would do--is about what people around would do

--

&amp;zwj;Measures: *How likely&lt;sup&gt;1&lt;/sup&gt; is it that people in your neighborhood would stop it if...*

   * "a group of neighborhood children were skipping school and hanging out on a street corner."
   * "some children were spray-painting graffiti on a local building."
   * "children were fighting out in the street."
   * "a child was showing disrespect to an adult."

.footnote[[1] (1) Very Likely, (2) Likely, (3) Unlikely, (4) Very Unlikely]

--

&amp;zwj;Assumption: *Shared variation in the measures represents underlying expectations for social control.*

---
class: inverse
# Measuring Relationships

---
# Types of Relationships

* &amp;zwj;Association: *X and Y tend to "go together"*
   + Ex: Ice cream sales and violent crime rise at same time
   + *May* imply common causes, e.g. temperature
   + *Does not* imply banning ice cream will reduce crime or vice versa
   + Purely observational--makes no assumptions

--

* &amp;zwj;Effect: *X causes Y*
   + Ex: Clearing a vacant lot reduces nearby violence 
   + Implies direction and cause:
      + Clearing more lots will reduce violence there
      + Reducing violence will not clear lots
   + Requires strong assumptions to identify

--

To measure an *effect*, you need to determine the difference in an outcome (Y) due solely to the cause of interest (X)

---
# Establishing Causation

&amp;zwj;Problem: We only observe *one outcome* per unit--if a person takes a pill, we don't see what happens when they don't take it.

???

Fundamental problem of causal inference

--

&amp;zwj;Solution: Randomized Treatment
* On average, randomly selected groups differ only by treatment.
* Average outcome difference between groups is treatment effect.

???

Randomization is incredibly powerful, overcoming almost any inferential obstacle where possible

--

.image-threequarterwidth[
![](img/rct.svg)
]

???

People may differ in any number of ways, but as long as those differences don't impact the likelihood of receiving treatment, you can get an accurate measure.

---
# Establishing Causation

&amp;zwj;*Hard Problem*: Most things we're interested in can't be randomly assigned.
* We can't assign rough childhoods neighborhood incomes.
* Other things related to our outcome (crime) are also related to treatment.

.image-threequarterwidth[
![](img/observational.svg)
]

???

Many things aren't just practically unassignable--many are impossible, like race.

There's a vigorous debate in literature over whether something which cannot be manipulated (in principle) can be a cause

Can't manipulate race... but can manipulate *perception* of race

--

&amp;zwj;*Hard Solution*: Measure everything else related and adjust for it.
* Hard to measure or even *know* everything related

???

This is basically the big barrier in observational, quantitative work

In qualitative work it can be easier to establish cause--but much harder to generalize

---
# Measuring Bias in Policing

### An example from Knox, Lowe, &amp; Mummolo. 2020. "Administrative Records Mask Racially Biased Policing"

---
# Use of Force


&amp;zwj;Question: Do police use more force against black civilians?

???

Note the effect here is really perceptions of race by police

--

Imagine you have sample of police encounters identical except for race.

*But* suppose bias leads police to:
1. Stop white civilians only for serious crimes
2. Stop black civilians with or without crime

--

Then, discard data on anyone police observed but *did not stop*.
+ You are now comparing use of force against white people committing serious crime to black ones committing no crime
+ If use of force were the same, *we'd have a serious problem*

--

*This is what police data actually show!*
* We only see the stopped people.
* There is no comparison group.


---
# What We Want

.image-threequarters[
![](img/bias_1.svg)
]

&amp;zwj;Question: How does race impact use of force?

---
# The Problem

.image-threequarters[
![](img/bias_2.svg)
]

Problems

* Race impacts likelihood of stop
* Race also impacts use of force
* Can't control for stops *because we never see unstopped people*


---
# It Gets Worse

.image-threequarters[
![](img/bias_complete.svg)
]

More problems

* Racial composition varies by neighborhood
* Police deployments and strategy vary by neighborhood
* Suspicion predicts both stops and use of force--and can't be observed

???

Some novel papers have gotten at these before, but it is incredibly challenging.

One example is comparing drivers stopped when sun is up to when sun is down--when police can't see race.

---
# Consequences

* Detecting bias in the decision to stop is difficult

   + Hit rate tests

???

Hit rate tests estimate differences between likelihood of, for example, a frisk resulting in a found gun by race of suspect

If guns found less often on black suspects, indicates bias

Not perfect because need to adjust for fact that black folks live in different places and police strategies differ

One important thing is using more objective outcome: arrests might be biased, finding a weapon can't be biased unless they planting.

--

* If any stop bias exists, it is difficult to measure bias in...

   + Arrests
   + Use of force
   + Frisks
   + Shootings

???

This is an issue many if not most researchers working in this area don't fully grasp

Vast majority of work in area does not account properly for this

--

* Raw numbers can easily show *opposite patterns* from underlying reality.

* Studies showing no bias--or anti-white bias--get *lots* of media, social media, and political traction.

???

Fryer paper making the rounds


---
# Summary

* Numbers *don't* speak for themselves

???

Administrative data are particularly problematic

They hide bias and can also be manipulated

--

* Methods should match the question

???

If you want to measure an effect or estimate the extent of something, it is probably quantitative

If you want to observe a mechanism, understand the meaning of things or motivations of people, it is probably quantitative

Most questions benefit from both--a common good practice is using quant methods but then doing qual work to examine cases that don't fit the model

--

* Methodological Things to Pay Attention to

   + Make sure concepts and operationalizations match up
   + Consider omitted variables
   + Consider missing data

???

Measures are important--bad measure invalidates everything after

--

* Interesting questions are hard

???

The most important questions in sociology, criminology, and public policy are either difficult or impossible to answer with an experiment.

Sometimes they're difficult or impossible to answer with observational data either.

---
class: inverse
# Discussion

---
# Some Questions

1. "Do you think reevaluating the way we understand crime statistics in the way Bronner suggests would be more effective in creating change? Would they be drastic enough to shock people into action? Or are statistics not that persuasive in getting people to dismantle structures that benefit them?"

2. "From the Reliance on Raw Statistics makes City Crime Rankings Misleading reading, it discusses a major factor affecting these numbers is its perception and relation to the law. How does this explain the situation of, mainly white people, escalating a situation by calling the police such as when black people barbecue or sell lemonade? How do we explain the police's response? Should there be a punishment from the caller?"

---

3. "From the Use of Official Records to Measure Crime &amp; Delinquency reading, it discusses several ways to access official records. How much information should be open for use for the safety of society while also considering the privacy of the individual? Should the offense matter in how much information should be released? Would that affect their rehabilitation?"

4. "'We need to think about this as this complex system. There are biases layered on biases… it just compounds way down the line,' political scientist Knox tells Laura Bronner. Systemic bias plagues our institutions so deeply, that even the methods we use to study its prevalence are systemically biased. What does this say about how we should confront structural inequality? Is it possible for our system to be reformed?"

---
# Some Clarifications

1. If trust in police is related to reporting crime, what does it mean for crime rates in minority neighborhoods? What characteristics are related to trust in police? And why how do we rely on these stats given underreporting?

???

Relationship between police trust and reporting varies. Black folks often report viewing police more in terms of hassle than distrust--they don't distrust them, but think they'll cause them more trouble. Not worth reporting minor stuff to deal with that.

Rates of less serious crime a lot higher in some minority neighborhoods than stats say. Probably pretty accurate for homicide.

Unerreporting is just a reality and these stats are all we have. Politicians, media, and voters probably rather have a biased measure than no measure. The numbers serve many purposes other than analytics.

--

2. If official statistics are inherently biased and misleading, and the organizations involved realize this, why are they still used? Is it to delude the public? Why are these all we have to work with and how can we change the system to be more accurate and reliable?

???

The official statistics do what the local agencies want them to do. As a service agency, the stats tell them how many citizen requests they get and how they're responding to them. They also provide actionable metrics that are politically useful.

We probably don't want to charge police with collecting better data--they have different incentives than us. Better to realize the reality of it and work with it. I can't imagine how we could get the police to report on everyone not stopped. Though solutions to current situation are very difficult.

In ideal world we'd have much more substantial survey and registry systems like some of the Scandinavian and European countries.

--

3. "Ehrenberg says ranking cities as safe or dangerous can be misleading, but still influences tourism and tax spending. Could this be a self-perpetuating cycle? Can tourists use their spending intentionally to make a difference in "high-crime" cities and neighborhoods?"

???

If you think about it, gentrification can represent something of this sort. Reinvestment in poor neighborhoods is good, but also need to be careful of second order consequences. It is a mixed bag.

--

4. "What are the fundamental characteristics of a good measure of crime? (Besides having every single data point possible)"

???

In an ideal world you'd have a measure that captures every *attempted* crime, whether it was *successful*, discovered, informally sanctioned, reported to police, and consequences.

---
# For Next Time

* Marshall, Chris E. 2002. “Deterrence Theory.” Pp. 512-515 in *Encyclopedia of Crime and Punishment*. Edited by D. Levinson. Beverly Hills: Sage

* Levitt, Steven D. 2002. “Deterrence.” Pp. 435-450 in *Crime: Public Policies for Crime Control*. Edited by J.Q. Wilson and J. Petersilia. Oakland, CA: ICS press



### Things to pay attention to:


* Connection to classical school

* Theoretical assumptions of deterrence

* Challenges for measuring deterrence

* Policy implications of deterrence
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "tomorrow-night-bright",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
